TITULO: -- DESARROLLO DE UN MODELO DE MACINE LEARNING PARA LA PREDICCION DE DISTRIBUCIONES DE TEMPERATURA EN UNA CHAPA --

1. Introducción (1–1.5 páginas)-------------------------------------------------------------------------------

	Contexto:
	
	Necesidad de predecir distribuciones de temperatura en placas.
	
	Limitaciones de métodos numéricos clásicos.
	
	Motivación:
	
	Uso de ML para predicción rápida y flexible.
	
	Objetivos:
	
	Generar dataset sintético confiable.
	
	Entrenar modelos de ML para predecir mapas de temperatura.
	
	Optimizar hiperparámetros y arquitectura.

2. Marco Teórico (1.5–2 páginas)------------------------------------------------------------------------------

	Breve sobre transferencia de calor estacionaria (solo contexto).
	
	Introducción a ML para predicción de campos escalares.
	
	Tipos de modelos ML posibles (MLP, CNN, UNet).
	
	Importancia de tuning de hiperparámetros (batch size, learning rate, arquitectura, regularización).

3. Metodología (3 páginas)------------------------------------------------------------------------------------

Descripcion del paso a paso que se siguio.

3.1 Generación de dataset (05/07/2025)

	Esta parte consiste en generar los datos necesarios para poder entrenar el modelo ML, lo que hago basicamene es definir de manera aleatoria las codiciones de contorno para los cuatro bordes de la chapa. Mi chapa tiene definidos los bordes A-B-C-D que pueden tomar como condicion de contorno un valor fijo de temperatura o un valor constante de flujo. Ademas, se tiene un punto caliente que esta definido por una pocision que es aleatoria en los puntos de la placa y un valor fijo de temperatura. Por ultimo, se tiene el valor de la conductividad termica  (k) que esta definido por el tipo de material de la chapa. 
	
	El primer paso consiste en generar de manera aleatoria valores para estas "doce variables moviles" (las variables fijas ... como la cantidad de nodos y el espaciamieto entre estos permanecen fijas para todas las muestras generadas). 
	
	Las variables generadas se definen en un funcion a rangos, para darle sentido fisico a la resolucion del problema. (MENCIONAR LOS RANGOS DE LAS VARIABLE) 
	
	(HABLAr DE LA CANTIDAD DE COMBINACIONES POSIBLES PARA LAS DOCE VARIABLES)
	
	Una vez que se tiene el conjunto de variables aleatorias, se resuelve el sistema, y se obtiene una matriz de 50 x 50 con los valores de temperatura calculados. El modelo de ML necsita tanto los datos de entrada (X) y salida (Y) para poder hacer el entrenamiento. 
	
	Esta secuencia de pasos se repite para una determinada cantidad de muestras .... obteniendose el dataset requerido. Sin embargo, aun queda pendiente el analisis de que ta consiste fisicamente es el dataset obtenido ... puesto que para determinadas combinacioes de las variables moviles se tienen resultados que son fisicamete inconsisitenetes. 
	
	Lo que se hace en este caso es incopoar un filtro antes 
	 
	
	Resumen de temp_chapa_P, condiciones, variables generadas.
	
	Estructura de entrada y salida para ML.
	
	Cantidad de muestras, rangos y validación.

3.2 Modelos de ML utilizados

	Arquitectura del MLP inicial (capas, activaciones).
	
	Variables de entrada seleccionadas:
	
	Ej: k, T_hotspot, coordenadas del hotspot, tipos de borde, valores de borde.

	Output: temperatura en cada nodo de la placa (flattened).

3.3 Proceso de entrenamiento

	Preprocesamiento de datos.
	
	División train/val/test.
	
	Configuración de entrenamiento:
	
	Optimizer (Adam).
	
	Loss (MSE).
	
	Epochs iniciales.

4. Resultados: Entrenamiento del Modelo ML (5 páginas)--------------------------------------------------------

4.1 Curvas de aprendizaje
	
	Pérdida (MSE, MAE) vs. epochs.
	
	Comportamiento en train vs. val.

4.2 Visualización de predicciones

	Mapas de temperatura predicho vs. real.
	
	Casos correctos vs. casos con error alto (ej., punto caliente).

4.3 Análisis de variables

	Importancia de cada variable de entrada (feature importance):
	
	Usar permutation importance o ablation (entrenar quitando variables).
	
	Correlación entre variables de entrada y error.

4.4 Optimización de hiperparámetros

	Variaciones de:
	
	Learning rate.
	
	Batch size.
	
	Número de capas y neuronas.
	
	Grid Search o búsqueda manual:
	
	Mostrar tabla comparativa de resultados.
	
	Analizar tiempo de entrenamiento vs. precisión.

5. Discusión (1.5 páginas)------------------------------------------------------------------------------------

	Comportamiento del modelo:
	
	Puntos fuertes (predicción en escalas, regiones planas).
	
	Dificultades (puntos calientes, extremos).
	
	Limitaciones:
	
	Representación de geometrías más complejas.
	
	Generalización fuera del dataset sintético.
	
	Impacto de las variables más relevantes.
	
	Potencial de escalamiento (más datos, arquitecturas complejas como CNN o UNet).

6. Conclusiones (1 página)------------------------------------------------------------------------------------

	Resumen de logros:
	
	Entrenamiento exitoso de modelo ML.
	
	Predicciones rápidas vs. métodos numéricos.
	
	Comprensión de la importancia de variables de entrada.
	
	Trabajos futuros:
	
	Incremento de datos con Numba/sparse para acelerar generación.
	
	Modelos CNN/UNet.
	
	Aplicación a geometrías complejas y condiciones variables.

7. Trabajos a futuro------------------------------------------------------------------------------------------

---- Dataset ---------------

	En la generacion del dataset, muchas de los muestras obtenidas no podian ser utilizadas para entrena el modelo ya que los resultados obtenidos eran fisiamente imposibles. Esto trajo el problema de que gran parte de las muestras generadas tenian que ser filtradas. 
	Para el dataset de 100 000 muestras con generacion de datos secuencial ... el 20% de muestras generadas no podia utilizace, es decir, se generaron 20 000 muestras (que ocupo un tiempo de alrededor de 2 horas) que debieron descartarce. 
	Visto este problema, lo que se debe hacer es incorporar filtros mas eficientes que consideren paa predecir en funcion de las variables de entrada que combinaciones de condiciones de contorno son las que generan estas muestras y filtrarlas antes de hacer el calculo de las temperaturas. Se deben buscar patrones de falla. 
	
7. Bibliografía (0.5 página)----------------------------------------------------------------------------------